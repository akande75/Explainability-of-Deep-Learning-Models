{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akande75/Explainability-of-Deep-Learning-Models/blob/main/adverts_Bin_Updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXo_xvY7kioN"
      },
      "source": [
        "# Explainability in Deep Learning models (Vehicle Image Classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQKp2WSyPVdG"
      },
      "source": [
        "# Importing Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Dp5NvAakm4h8"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, BatchNormalization, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import warnings\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "# Set TensorFlow to not show unnecessary logs\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hm1gnjQvy82p"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcjaWwAF0RFb"
      },
      "source": [
        "### Loading Dataset from File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yW26PVDTSMw6"
      },
      "outputs": [],
      "source": [
        "# Loading data from the file path\n",
        "train_dataset_path = '/content/drive/MyDrive/Data/train'\n",
        "val_dataset_path = '/content/drive/MyDrive/Data/pred'\n",
        "test_dataset_path = '/content/drive/MyDrive/Data/test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRp8oWCZ0Yxf"
      },
      "source": [
        "### Performing some data Augumentation on the training, validation and test datasets\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnsakUGADyKM"
      },
      "outputs": [],
      "source": [
        "#Data Augumentation\n",
        "\n",
        "\n",
        "# Defining image dimensions\n",
        "width = 224\n",
        "height = 224\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,  # Adding Horizontal flip for symmetry\n",
        "    vertical_flip=False,   # Excluding Vertical Flip\n",
        "    rotation_range=0,      # No rotation for now . Exploring different degrees\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dataset_path,\n",
        "    target_size=(width, height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Printing the class indices to ensure classes are loaded correctly\n",
        "print(train_generator.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfWyP5nmEdb-"
      },
      "outputs": [],
      "source": [
        "val_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,  # Horizontal flip for symmetry\n",
        "    vertical_flip=False,   # Vertical flip might not be appropriate for medical images\n",
        "    rotation_range=0,      # No rotation for now (adjust if needed)\n",
        "    fill_mode='nearest'\n",
        "    )\n",
        "val_generator = val_datagen.flow_from_directory(val_dataset_path,\n",
        "                                                   target_size=(width, height),\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='binary',\n",
        "                                                    shuffle=True)\n",
        "\n",
        "# Printing the class indices to ensure classes are loaded correctly\n",
        "print(val_generator.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0K98LzpUgGtq"
      },
      "outputs": [],
      "source": [
        "#Data Augumentation\n",
        "\n",
        "# Defining image dimensions\n",
        "width = 224\n",
        "height = 224\n",
        "batch_size = 32\n",
        "\n",
        "test_datagen = ImageDataGenerator( rescale=1.0/255,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,  # Horizontal flip for symmetry\n",
        "    vertical_flip=False,   # Vertical flip might not be appropriate for medical images\n",
        "    rotation_range=0,      # No rotation for now (adjust if needed)\n",
        "    fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(test_dataset_path,\n",
        "                                                   target_size=(width, height),\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='binary',\n",
        "                                                    shuffle=True)\n",
        "\n",
        "# Printing the class indices to ensure classes are loaded correctly\n",
        "print(test_generator.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GdV9zLa1Z7x"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def count_images_per_class(generator):\n",
        "    # Collect labels from generator\n",
        "    labels = []\n",
        "    # Iterate over batches\n",
        "    for _, batch_labels in generator:\n",
        "        labels.extend(batch_labels)\n",
        "        # Stop if we've gone through the entire dataset\n",
        "        if len(labels) >= generator.samples:\n",
        "            break\n",
        "\n",
        "    # Since the labels are binary, they will either be 0 or 1 (no need for argmax)\n",
        "    labels = [int(label) for label in labels]\n",
        "\n",
        "    # Count the occurrences of each class (0 and 1)\n",
        "    class_counts = Counter(labels)\n",
        "\n",
        "    # Convert to dictionary for easier access\n",
        "    class_counts_dict = dict(class_counts)\n",
        "\n",
        "    return class_counts_dict\n",
        "\n",
        "# Example usage with the train_generator and test_generator\n",
        "train_class_counts = count_images_per_class(train_generator)\n",
        "val_class_counts = count_images_per_class(val_generator)\n",
        "\n",
        "# Get class names from the generator's class_indices attribute (binary classification should only have two classes)\n",
        "class_names = list(train_generator.class_indices.keys())\n",
        "\n",
        "# Map class index to names for both train and test datasets\n",
        "train_class_counts_named = {class_names[i]: count for i, count in train_class_counts.items()}\n",
        "val_class_counts_named = {class_names[i]: count for i, count in val_class_counts.items()}\n",
        "\n",
        "# Print the class distribution for training and validation datasets\n",
        "print(\"Number of images per class in training set:\", train_class_counts_named)\n",
        "print(\"Number of images per class in Validation set:\", val_class_counts_named)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbiTadFtP_6m"
      },
      "source": [
        "### Viewing sample loaded images from the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXT1W-Fnziqq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define function to display images\n",
        "def imshow(images, labels, class_indices):\n",
        "    \"\"\"Display images with labels.\"\"\"\n",
        "    fig, axes = plt.subplots(1, len(images), figsize=(20, 20))\n",
        "    for img, lbl, ax in zip(images, labels, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.set_title(class_indices[lbl])\n",
        "        ax.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Get a batch of training data\n",
        "images, labels = next(train_generator)\n",
        "images = images[:10]  # Get first 10 images\n",
        "labels = labels[:10]  # Use corresponding labels directly if they are class indices\n",
        "\n",
        "# Map class indices to class names\n",
        "class_indices = {v: k for k, v in train_generator.class_indices.items()}\n",
        "\n",
        "# Display images\n",
        "imshow(images, labels, class_indices)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIKvkp3KQeND"
      },
      "source": [
        "### Implementing Sequential CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sANObmwjDw1O"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, BatchNormalization, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(filters=32, kernel_size=(3, 3), padding='valid', input_shape=(224, 224, 3)),\n",
        "        Activation('relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        BatchNormalization(),\n",
        "\n",
        "        Conv2D(filters=64, kernel_size=(3, 3), padding='valid', kernel_regularizer=l2(0.00005)),\n",
        "        Activation('relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        BatchNormalization(),\n",
        "\n",
        "        Conv2D(filters=128, kernel_size=(3, 3), padding='valid', kernel_regularizer=l2(0.00005)),\n",
        "        Activation('relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        BatchNormalization(),\n",
        "\n",
        "        Conv2D(filters=256, kernel_size=(3, 3), padding='valid', kernel_regularizer=l2(0.00005)),\n",
        "        Activation('relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        BatchNormalization(),\n",
        "\n",
        "        Flatten(),\n",
        "\n",
        "        Dense(units=256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "\n",
        "        # Final layer for binary classification\n",
        "        Dense(units=1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqOE1qx2Whzf"
      },
      "source": [
        "### Training Sequential CNN Model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wchFX9sfIk8j"
      },
      "outputs": [],
      "source": [
        "from tqdm.keras import TqdmCallback\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "\n",
        "# Define a custom TQDM progress bar callback\n",
        "class TQDMProgressBar(TqdmCallback):\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.epochs = self.params['epochs']\n",
        "        self.epoch_bar = tqdm(total=self.epochs, desc='Epochs', position=0)\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.steps = self.params['steps']\n",
        "        self.batch_bar = tqdm(total=self.steps, desc=f'Epoch {epoch + 1}/{self.epochs}', position=1, leave=False)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.epoch_bar.update(1)\n",
        "        self.batch_bar.close()\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        self.batch_bar.update(1)\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        self.epoch_bar.close()\n",
        "\n",
        "tqdm_progress_bar = TQDMProgressBar()\n",
        "\n",
        "# Create model (assuming 'create_model' function is defined elsewhere)\n",
        "cnn_model = create_model()\n",
        "\n",
        "# Compile the model\n",
        "cnn_model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss=binary_crossentropy,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Define callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), patience=5)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "Model_Train = cnn_model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator,\n",
        "    verbose=0,  # Disable built-in verbose to use custom tqdm callback\n",
        "    callbacks=[reduce_lr, early_stopping, tqdm_progress_bar]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w54c3eLxInvC"
      },
      "outputs": [],
      "source": [
        "# printing model summary\n",
        "print(cnn_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywCPdlIDNArV"
      },
      "outputs": [],
      "source": [
        "#printing model results\n",
        "train_accuracy = Model_Train.history['accuracy']\n",
        "val_accuracy = Model_Train.history['val_accuracy']\n",
        "\n",
        "train_loss = Model_Train.history['loss']\n",
        "val_loss = Model_Train.history['val_loss']\n",
        "\n",
        "# Print training and validation metrics in a formatted manner\n",
        "print(\"Epoch | Train Accuracy | Val Accuracy | Train Loss | Val Loss\")\n",
        "print(\"-\" * 50)  # Print a line separator\n",
        "\n",
        "for epoch in range(len(train_accuracy)):\n",
        "    print(f\"{epoch + 1:>5} | {train_accuracy[epoch]:<14.4f} | {val_accuracy[epoch]:<12.4f} | {train_loss[epoch]:<10.4f} | {val_loss[epoch]:<8.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-kfxm5K8Zxm"
      },
      "source": [
        "### Plotting Train Loss and Accuracy Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMbQ5AqpJit9"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(train_loss, label='Train Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plotting the accuracy curves\n",
        "plt.figure()\n",
        "plt.plot(train_accuracy, label='Train Accuracy')\n",
        "plt.plot(val_accuracy , label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Train and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTzVDidac8Wl"
      },
      "source": [
        "### Implementing Pre-Trained VGG16 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qU9Wz2-Jit-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tqdm.keras import TqdmCallback\n",
        "\n",
        "# Define the VGG16 model for binary classification\n",
        "def create_vgg16_model(input_shape):\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # Binary classification: 1 output with sigmoid activation\n",
        "    predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define input shape (224x224x3)\n",
        "width, height = 224, 224\n",
        "input_shape = (width, height, 3)\n",
        "\n",
        "# Create the VGG16 model for binary classification\n",
        "vgg16_model = create_vgg16_model(input_shape)\n",
        "\n",
        "# Compile the model for binary classification\n",
        "vgg16_model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss=BinaryCrossentropy(),  # Use binary cross-entropy for binary classification\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Define callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), patience=5, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "tqdm_progress_bar = TqdmCallback()\n",
        "\n",
        "# Train the model\n",
        "Model_Train = vgg16_model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator,\n",
        "    verbose=0,  # Using custom tqdm callback for progress bar\n",
        "    callbacks=[reduce_lr, early_stopping, tqdm_progress_bar]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECc-tkWdhYov"
      },
      "outputs": [],
      "source": [
        "# printing the model summary\n",
        "print(vgg16_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHedR0ZId_-4"
      },
      "outputs": [],
      "source": [
        "train_accuracy = Model_Train.history['accuracy']\n",
        "val_accuracy = Model_Train.history['val_accuracy']\n",
        "\n",
        "train_loss = Model_Train.history['loss']\n",
        "val_loss = Model_Train.history['val_loss']\n",
        "\n",
        "# Print training and validation metrics in a formatted manner\n",
        "print(\"Epoch | Train Accuracy | Val Accuracy | Train Loss | Val Loss\")\n",
        "print(\"-\" * 50)  # Print a line separator\n",
        "\n",
        "for epoch in range(len(train_accuracy)):\n",
        "    print(f\"{epoch + 1:>5} | {train_accuracy[epoch]:<14.4f} | {val_accuracy[epoch]:<12.4f} | {train_loss[epoch]:<10.4f} | {val_loss[epoch]:<8.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkgL6etLgsON"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(train_loss, label='Train Loss')\n",
        "plt.plot(val_loss , label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plotting the accuracy curves\n",
        "plt.figure()\n",
        "plt.plot(train_accuracy, label='Train Accuracy')\n",
        "plt.plot(val_accuracy, label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Train and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFlCSqDGh1J9"
      },
      "source": [
        "### Implementing Pre-Trained RestNet50 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyL2A93phDtZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tqdm.keras import TqdmCallback\n",
        "\n",
        "# Define the ResNet50 model for binary classification\n",
        "def create_resnet50_model(input_shape):\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # Binary classification: 1 output with sigmoid activation\n",
        "    predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define input shape (e.g., 224x224x3)\n",
        "width, height = 224, 224\n",
        "input_shape = (width, height, 3)\n",
        "\n",
        "# Create ResNet50 model for binary classification\n",
        "resnet50_model = create_resnet50_model(input_shape)\n",
        "\n",
        "# Compile the model for binary classification\n",
        "resnet50_model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss=BinaryCrossentropy(),  # Use binary cross-entropy for binary classification\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Define callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), patience=5, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "tqdm_progress_bar = TqdmCallback()\n",
        "\n",
        "# Train the model\n",
        "Model_Train = resnet50_model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator,\n",
        "    verbose=0,  # Use custom tqdm callback for progress bar\n",
        "    callbacks=[reduce_lr, early_stopping, tqdm_progress_bar]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zm6T7HbNkC-0"
      },
      "outputs": [],
      "source": [
        "print(resnet50_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaUqZQhgh3_F"
      },
      "outputs": [],
      "source": [
        "train_accuracy = Model_Train.history['accuracy']\n",
        "val_accuracy = Model_Train.history['val_accuracy']\n",
        "\n",
        "train_loss = Model_Train.history['loss']\n",
        "val_loss = Model_Train.history['val_loss']\n",
        "\n",
        "# Print training and validation metrics in a formatted manner\n",
        "print(\"Epoch | Train Accuracy | Val Accuracy | Train Loss | Val Loss\")\n",
        "print(\"-\" * 50)  # Print a line separator\n",
        "\n",
        "for epoch in range(len(train_accuracy)):\n",
        "    print(f\"{epoch + 1:>5} | {train_accuracy[epoch]:<14.4f} | {val_accuracy[epoch]:<12.4f} | {train_loss[epoch]:<10.4f} | {val_loss[epoch]:<8.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpXIQsqLjiy_"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(train_loss, label='RESTNET Train Loss')\n",
        "plt.plot(val_loss , label='RESTNET Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plotting the accuracy curves\n",
        "plt.figure()\n",
        "plt.plot(train_accuracy, label='RESTNET Train Accuracy')\n",
        "plt.plot(val_accuracy, label='RESTNET Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Train and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lThCm-DCCsU"
      },
      "source": [
        "### Predicting Test Image using VGG16 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5Dyo-i_MLeJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Number of top predictions to display (since it's binary, we can show two)\n",
        "top_n = 2\n",
        "\n",
        "# Make predictions on the test data\n",
        "test_predictions = vgg16_model.predict(test_generator, verbose=1)\n",
        "\n",
        "# Get class labels from the test generator\n",
        "class_indices = test_generator.class_indices\n",
        "labels = list(class_indices.keys())  # Should be ['class_0', 'class_1']\n",
        "\n",
        "# Get a batch of images from the test generator\n",
        "images, _ = next(test_generator)\n",
        "\n",
        "# Rescale the images if needed (e.g., if rescaled in generator)\n",
        "images = images * 255.0  # Reverse normalization if applied in the generator\n",
        "\n",
        "# Create a plot with 2 rows and 5 columns\n",
        "num_images = len(images)\n",
        "n_rows = 2\n",
        "n_cols = 5\n",
        "fig, ax = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(15, 6))\n",
        "\n",
        "# Adjust the number of images to be displayed based on batch size\n",
        "idx = 0\n",
        "for i in range(n_rows):  # Loop over rows\n",
        "    for j in range(n_cols):  # Loop over columns\n",
        "        if idx >= num_images:  # If there are no more images to plot\n",
        "            ax[i, j].axis(\"off\")  # Turn off the axis for unused subplots\n",
        "            continue\n",
        "\n",
        "        # Get the predicted probability for the positive class\n",
        "        prob = test_predictions[idx][0]  # Only one output for binary classification\n",
        "        pred_class = labels[1] if prob > 0.5 else labels[0]  # Assign class based on threshold\n",
        "\n",
        "        # Create a title string with the prediction\n",
        "        title = f\"Predicted: {pred_class}\\nProb: {prob:.2f}\"\n",
        "\n",
        "        # Plot the image and set the title\n",
        "        ax[i, j].imshow(images[idx].astype(\"uint8\"))  # Ensure the image is in uint8 for correct display\n",
        "        ax[i, j].set_title(title, fontsize=10)\n",
        "        ax[i, j].axis(\"off\")  # Turn off the axis\n",
        "        idx += 1\n",
        "\n",
        "# Adjust layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.suptitle(\"Test Dataset Predictions for Each Image\", fontsize=20)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPQq4QTupdsF"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Step 1: Generate predictions from the model and true labels from the test generator\n",
        "y_true = test_generator.classes  # True labels from test generator\n",
        "y_pred = vgg16_model.predict(test_generator)  # Model predictions\n",
        "\n",
        "# Step 2: Convert predicted probabilities to class labels\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Step 3: Create a figure with subplots\n",
        "fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(15, 8))\n",
        "test_images = np.asarray(test_generator.filenames)  # Get test images' filenames\n",
        "\n",
        "# Step 4: Loop over the subplots to show both correct and incorrect predictions\n",
        "for i in range(2):\n",
        "    for j in range(5):\n",
        "        idx = np.random.randint(0, len(y_true))  # Randomly pick an image index\n",
        "        true_label = list(test_generator.class_indices.keys())[y_true[idx]]\n",
        "        predicted_label = list(test_generator.class_indices.keys())[y_pred_classes[idx]]\n",
        "\n",
        "        # Define if prediction is correct or wrong\n",
        "        if y_true[idx] == y_pred_classes[idx]:\n",
        "            title = f\"Correct\\nTrue: {true_label}\\nPred: {predicted_label}\"\n",
        "        else:\n",
        "            title = f\"Wrong\\nTrue: {true_label}\\nPred: {predicted_label}\"\n",
        "\n",
        "        # Read and display the image\n",
        "        img_path = os.path.join(test_generator.directory, test_images[idx])\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "\n",
        "        ax[i, j].imshow(img)\n",
        "        ax[i, j].set_title(title, fontsize=10)\n",
        "        ax[i, j].axis(\"off\")\n",
        "\n",
        "# Step 5: Adjust layout and show\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Predictions on Test Set', fontsize=20)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_rCHwCs78-x"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set\n",
        "results = vgg16_model.evaluate(test_generator, batch_size=batch_size)\n",
        "\n",
        "# Print all returned values to see what is being returned\n",
        "print(f\"Evaluation Results: {results}\")\n",
        "\n",
        "# If 'results' contains more values (e.g., other metrics), you can extract specific ones\n",
        "test_loss = results[0]  # Assuming the first value is loss\n",
        "test_accuracy = results[1]  # Assuming the second value is accuracy\n",
        "\n",
        "print(f\"Test Loss:     {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaSN5j7CrZrP"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGARGhAqrkIY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# Step 1: Generate predictions from the model and true labels from the test generator\n",
        "y_true = test_generator.classes  # True labels from test generator\n",
        "y_pred = vgg16_model.predict(test_generator)  # Model predictions\n",
        "\n",
        "# Step 2: Convert predicted probabilities to class labels\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Step 3: Calculate confusion matrix\n",
        "cf_mtx = confusion_matrix(y_true, y_pred_classes)\n",
        "labels = list(test_generator.class_indices.keys())\n",
        "\n",
        "# Step 4: Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cf_mtx, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicted Class')\n",
        "plt.ylabel('True Class')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0m4WMo_-qDI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert y_true and y_pred to integers if necessary\n",
        "y_true = [int(label) for label in y_true]\n",
        "y_pred = [int(label) for label in y_pred]\n",
        "\n",
        "# List to store true vs predicted class names\n",
        "true_vs_pred = []\n",
        "\n",
        "# Assuming labels is a list of class names, for example: ['Class A', 'Class B']\n",
        "for true_label, predicted_label in zip(y_true, y_pred):\n",
        "    true_class = labels[true_label] if true_label < len(labels) else 'Unknown'\n",
        "    pred_class = labels[predicted_label] if predicted_label < len(labels) else 'Unknown'\n",
        "    true_vs_pred.append([true_class, pred_class])\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(true_vs_pred, columns=['True Class', 'Predicted Class'])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAVRLVd6C8XX"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming labels is a list, e.g., labels = ['Class A', 'Class B']\n",
        "print(classification_report(y_true, y_pred, target_names=labels))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bqGw4-clGRe"
      },
      "source": [
        "## Explainability with Gradient Activation Mapping (Grad-CAM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "He1WSxOwlIzq"
      },
      "outputs": [],
      "source": [
        "# Grad-CAM implementation\n",
        "last_conv_layer = vgg16_model.get_layer('block5_conv3')  # For VGG16; adjust if using ResNet50\n",
        "# last_conv_layer = model.get_layer('conv5_block3_out') # Use this if using\n",
        "# ResNet50 %%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9Yd3Ngwm_k_"
      },
      "outputs": [],
      "source": [
        "# Create a model that maps the input image to the activations of the last conv layer and the output predictions\n",
        "grad_model = Model([vgg16_model.inputs], [last_conv_layer.output, vgg16_model.output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4MA3EeInnUL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "def grad_cam(grad_model, img_array, last_conv_layer_name, predicted_class):\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        tape.watch(conv_outputs)\n",
        "        loss = predictions[:, predicted_class]\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    conv_outputs *= pooled_grads.numpy()\n",
        "    heatmap = tf.reduce_mean(conv_outputs, axis=-1).numpy()\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap /= np.max(heatmap) if np.max(heatmap) > 0 else 1\n",
        "    return heatmap\n",
        "\n",
        "def preprocess_image(img_path, target_size=(224, 224)):\n",
        "    img = load_img(img_path, target_size=target_size)\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return preprocess_input(img_array)\n",
        "\n",
        "# Define paths and models\n",
        "img_path = '/content/drive/MyDrive/Data/test/No_Contact/5dc58956cff54f80a86b189608fe5734.jpg'\n",
        "last_conv_layer_name = 'block5_conv3'\n",
        "\n",
        "# Load VGG16 model pre-trained on ImageNet data\n",
        "vgg16_model = tf.keras.applications.VGG16(weights='imagenet')\n",
        "\n",
        "# Create a grad model that outputs the last convolutional layer's activations and the final predictions\n",
        "grad_model = tf.keras.Model(\n",
        "    inputs=[vgg16_model.inputs],\n",
        "    outputs=[vgg16_model.get_layer(last_conv_layer_name).output, vgg16_model.output]\n",
        ")\n",
        "\n",
        "# Preprocess the image and make predictions\n",
        "img_array = preprocess_image(img_path)\n",
        "predictions = grad_model(img_array)[1]\n",
        "predicted_class = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "# Generate the heatmap using Grad-CAM\n",
        "heatmap = grad_cam(grad_model, img_array, last_conv_layer_name, predicted_class)\n",
        "\n",
        "# Load and prepare the original image\n",
        "original_img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Resize heatmap to match the original image size\n",
        "heatmap_resized = cv2.resize(heatmap, (original_img.shape[1], original_img.shape[0]))\n",
        "\n",
        "# Convert heatmap to an 8-bit image\n",
        "heatmap_resized = np.uint8(255 * heatmap_resized)\n",
        "\n",
        "# Apply color mapping to the heatmap\n",
        "heatmap_resized = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)\n",
        "\n",
        "# Superimpose the heatmap on the original image\n",
        "superimposed_img = np.clip(heatmap_resized * 0.4 + original_img, 0, 255).astype('uint8')\n",
        "\n",
        "# Save the superimposed image\n",
        "cv2.imwrite('grad_cam_output.jpg', superimposed_img)\n",
        "\n",
        "# Plot the original image, superimposed image, and resized CAM plot (last)\n",
        "plt.figure(figsize=(30, 10))\n",
        "\n",
        "# Plot the original image\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title('Original Image')\n",
        "plt.imshow(original_img)\n",
        "plt.axis('off')\n",
        "\n",
        "# Plot the superimposed image\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.title('Superimposed Image with Heatmap')\n",
        "plt.imshow(superimposed_img)\n",
        "plt.axis('off')\n",
        "\n",
        "# Plot the resized heatmap (CAM) in the last position\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.title('Class Activation Map (CAM)')\n",
        "plt.imshow(heatmap_resized, cmap='jet')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyTBro_KDQLp"
      },
      "outputs": [],
      "source": [
        "def grad_cam(grad_model, img_array, last_conv_layer_name, predicted_class):\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        tape.watch(conv_outputs)\n",
        "        loss = predictions[:, predicted_class]\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    conv_outputs *= pooled_grads.numpy()\n",
        "    heatmap = tf.reduce_mean(conv_outputs, axis=-1).numpy()\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap /= np.max(heatmap) if np.max(heatmap) > 0 else 1\n",
        "    return heatmap\n",
        "\n",
        "def preprocess_image(img_path, target_size=(224, 224)):\n",
        "    img = load_img(img_path, target_size=target_size)\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return preprocess_input(img_array)\n",
        "\n",
        "# Define paths and models\n",
        "img_path = '/content/drive/MyDrive/Data/test/No_Contact/5dc58956cff54f80a86b189608fe5734.jpg'\n",
        "last_conv_layer_name = 'block5_conv3'\n",
        "\n",
        "# Load VGG16 model pre-trained on ImageNet data\n",
        "vgg16_model = tf.keras.applications.VGG16(weights='imagenet')\n",
        "\n",
        "# Create a grad model that outputs the last convolutional layer's activations and the final predictions\n",
        "grad_model = tf.keras.Model(\n",
        "    inputs=[vgg16_model.inputs],\n",
        "    outputs=[vgg16_model.get_layer(last_conv_layer_name).output, vgg16_model.output]\n",
        ")\n",
        "\n",
        "# Preprocess the image and make predictions\n",
        "img_array = preprocess_image(img_path)\n",
        "predictions = grad_model(img_array)[1]\n",
        "predicted_class = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "# Generate the heatmap using Grad-CAM\n",
        "heatmap = grad_cam(grad_model, img_array, last_conv_layer_name, predicted_class)\n",
        "\n",
        "# Load and prepare the original image\n",
        "original_img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Resize heatmap to match the original image size\n",
        "heatmap_resized = cv2.resize(heatmap, (original_img.shape[1], original_img.shape[0]))\n",
        "\n",
        "# Convert heatmap to an 8-bit image\n",
        "heatmap_resized = np.uint8(255 * heatmap_resized)\n",
        "\n",
        "# Apply color mapping to the heatmap\n",
        "heatmap_resized = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)\n",
        "\n",
        "# Superimpose the heatmap on the original image\n",
        "superimposed_img = np.clip(heatmap_resized * 0.4 + original_img, 0, 255).astype('uint8')\n",
        "\n",
        "# Save the superimposed image\n",
        "cv2.imwrite('grad_cam_output.jpg', superimposed_img)\n",
        "\n",
        "# Plot the original image, superimposed image, and resized CAM plot (last)\n",
        "plt.figure(figsize=(30, 10))\n",
        "\n",
        "# Plot the original image\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title('Original Image')\n",
        "plt.imshow(original_img)\n",
        "plt.axis('off')\n",
        "\n",
        "# Plot the superimposed image\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.title('Superimposed Image with Heatmap')\n",
        "plt.imshow(superimposed_img)\n",
        "plt.axis('off')\n",
        "\n",
        "# Plot the resized heatmap (CAM) in the last position\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.title('Class Activation Map (CAM)')\n",
        "plt.imshow(heatmap_resized, cmap='jet')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7cd8vMhTZh_"
      },
      "source": [
        "### Adding Custom Layer to the Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qU6hhA4yIlP"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tqdm.keras import TqdmCallback\n",
        "\n",
        "# Define the VGG16 model for binary classification\n",
        "def create_vgg16_model(input_shape):\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # Binary classification: 1 output with sigmoid activation\n",
        "    predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define input shape (224x224x3)\n",
        "width, height = 224, 224\n",
        "input_shape = (width, height, 3)\n",
        "\n",
        "# Create the VGG16 model for binary classification\n",
        "vgg16_model = create_vgg16_model(input_shape)\n",
        "\n",
        "# Compile the model for binary classification\n",
        "vgg16_model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss=BinaryCrossentropy(),  # Use binary cross-entropy for binary classification\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Define callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), patience=5, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "tqdm_progress_bar = TqdmCallback()\n",
        "\n",
        "# Train the model\n",
        "Model_Train = vgg16_model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator,\n",
        "    verbose=0,  # Using custom tqdm callback for progress bar\n",
        "    callbacks=[reduce_lr, early_stopping, tqdm_progress_bar]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vmYKCATlTlEe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Number of top predictions to display (since it's binary, we can show two)\n",
        "top_n = 2\n",
        "\n",
        "# Make predictions on the test data\n",
        "test_predictions = vgg16_model.predict(test_generator, verbose=1)\n",
        "\n",
        "# Get class labels from the test generator\n",
        "class_indices = test_generator.class_indices\n",
        "labels = list(class_indices.keys())  # Should be ['class_0', 'class_1']\n",
        "\n",
        "# Get a batch of images from the test generator\n",
        "images, _ = next(test_generator)\n",
        "\n",
        "# Rescale the images if needed (e.g., if rescaled in generator)\n",
        "images = images * 255.0  # Reverse normalization if applied in the generator\n",
        "\n",
        "# Create a plot with 2 rows and 5 columns\n",
        "num_images = len(images)\n",
        "n_rows = 2\n",
        "n_cols = 5\n",
        "fig, ax = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(15, 6))\n",
        "\n",
        "# Adjust the number of images to be displayed based on batch size\n",
        "idx = 0\n",
        "for i in range(n_rows):  # Loop over rows\n",
        "    for j in range(n_cols):  # Loop over columns\n",
        "        if idx >= num_images:  # If there are no more images to plot\n",
        "            ax[i, j].axis(\"off\")  # Turn off the axis for unused subplots\n",
        "            continue\n",
        "\n",
        "        # Get the predicted probability for the positive class\n",
        "        prob = test_predictions[idx][0]  # Only one output for binary classification\n",
        "        pred_class = labels[1] if prob > 0.5 else labels[0]  # Assign class based on threshold\n",
        "\n",
        "        # Create a title string with the prediction\n",
        "        title = f\"Predicted: {pred_class}\\nProb: {prob:.2f}\"\n",
        "\n",
        "        # Plot the image and set the title\n",
        "        ax[i, j].imshow(images[idx].astype(\"uint8\"))  # Ensure the image is in uint8 for correct display\n",
        "        ax[i, j].set_title(title, fontsize=10)\n",
        "        ax[i, j].axis(\"off\")  # Turn off the axis\n",
        "        idx += 1\n",
        "\n",
        "# Adjust layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.suptitle(\"Test Dataset Predictions for Each Image\", fontsize=20)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdXJZ9QuUbcn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1UOW2xf7P6cztyb58QwG22syvTQcSqyp9",
      "authorship_tag": "ABX9TyPDcw6zFPHlRd0/bafLW6AO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}